{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "data_frame= pd.read_table(\"SMSSpamCollection\",header= None, encoding ='utf-8') \n",
    "print(data_frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go jurong point crazy available bugis n great ...\n",
      "1                                 ok lar joking wif u oni\n",
      "2       free entry number wkly comp win fa cup final t...\n",
      "3                     u dun say early hor u c already say\n",
      "4                     nah think go usf life around though\n",
      "                              ...                        \n",
      "5567    numbernd time tried number contact u u number ...\n",
      "5568                          ü b going esplanade fr home\n",
      "5569                                 pity mood suggestion\n",
      "5570    guy bitching acted like interested buying some...\n",
      "5571                                       rofl true name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "classes= le.fit_transform(data_frame[0])\n",
    "\n",
    "#replacing email, phonr No, money, webaddress, number, puntuation, more than single space, leading and trailing white space\n",
    "emails= data_frame[1]\n",
    "\n",
    "emails= emails.str.replace(r'^\\w+@[a-zA-Z_]+?\\.[a-zA-Z]{2,3}$', 'emailaddress')\n",
    "emails= emails.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumber')\n",
    "emails= emails.str.replace(r'^£|\\$', 'money')\n",
    "emails= emails.str.replace(r'\\d+(\\.\\d+)?','number')\n",
    "emails= emails.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
    "emails= emails.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "emails= emails.str.replace(r'\\s+', ' ')\n",
    "emails= emails.str.replace(r'^\\s+|\\s+?$', '')\n",
    "emails= emails.str.lower()\n",
    "\n",
    "# remove stop words from text messages\n",
    "from nltk.corpus import stopwords\n",
    "stop_words= list(stopwords.words('english'))\n",
    "emails=emails.apply(lambda x: ' '.join(i for i in x.split() if i not in stop_words))\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "emails=emails.apply(lambda x: ' '.join(lemmatizer.lemmatize(i) for i in x.split()))\n",
    "\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=list()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "for i in emails:\n",
    "    words= word_tokenize(i)\n",
    "    for k in words: new.append(k)\n",
    "freq_words = nltk.FreqDist( new)\n",
    "freq_words.most_common() \n",
    "feature_words=list(freq_words.keys())[:1500]\n",
    "def features(msg):\n",
    "    words= word_tokenize(msg)\n",
    "    features= {}\n",
    "    for i in feature_words:\n",
    "        features[i]= (i in words)\n",
    "    return features\n",
    "data_set= zip(emails, classes)\n",
    "feature_msgs=[(features(emails), y) for(emails,y) in data_set]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900\n",
      "1672\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(feature_msgs, test_size = 0.30)\n",
    "print(len(training))\n",
    "print(len(testing))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1465\n",
      "           1       0.90      0.95      0.92       207\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.95      0.97      0.96      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = SklearnClassifier(MultinomialNB()).train(training)\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "test_features, labels = zip(*testing)\n",
    "predictions= model.classify_many(test_features)\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
